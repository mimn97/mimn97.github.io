---
layout: project
title: Image Captioning with BERT
subtitle: "Does BERT improve the quality of generated captions of images?"
---

(*This work is the final project for the course 'Neural Networks' at UMass Amherst during Fall 2021.*)

The task of image caption generation requires an accurate understanding of visual objects and textual expression of that scene understanding. Recently, several prominent methods have been developed to resolve the task of generating image captions, inspired by the invention of attention-based approaches and pre-trained language models. In this paper, we implemented our baseline model of the captioning task, the encoder-decoder network integrated with soft-attention concepts. As an extended approach to the captioning task, we also integrated pre-trained word embeddings of BERT into this baseline model to enhance the performance of the baseline soft-attention model. We trained and evaluated these two captioning models on the Microsoft COCO 2014 train/validation images. During our experiments, we confirmed that the soft-attention model integrated with BERT's pre-trained embeddings outperforms the baseline soft-attention model by reducing cross-entropy loss of the baseline model in half and increasing BLEU scores significantly.  


[*Project Report*](/assets/projects/nn_682/report.pdf) (*Received the perfect score for the course.) 